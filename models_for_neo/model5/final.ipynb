{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344ced9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with enhanced recommendations saved to: D:\\data\\enhanced_student_recommendations.csv\n",
      "Recommendation model saved to: D:\\data\\recommendation_model.pkl\n",
      "\n",
      "Sample of the updated data (first 5 rows):\n",
      "  Student ID  CGPA             Past Events   Interest Domain  \\\n",
      "0     S00001  8.94                      []   Cloud Computing   \n",
      "1     S00002  7.20            [Blockchain]  Embedded Systems   \n",
      "2     S00003  9.32                 [AI/ML]               IoT   \n",
      "3     S00004  5.25          [AI/ML, AR/VR]   Web Development   \n",
      "4     S00005  6.05  [Cloud Computing, IoT]               IoT   \n",
      "\n",
      "   Performance Score          Recommended Events  \\\n",
      "0                 58  [Cloud Computing Workshop]   \n",
      "1                 47                          []   \n",
      "2                 40                          []   \n",
      "3                 49                          []   \n",
      "4                 59                          []   \n",
      "\n",
      "                                             Message  \n",
      "0  We recommend attending high-quality events in ...  \n",
      "1  Focus on academics first. If you wish to atten...  \n",
      "2  Focus on academics first. If you wish to atten...  \n",
      "3  Focus on academics first. If you wish to atten...  \n",
      "4  Focus on academics first. If you wish to atten...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = r\"D:\\data\\generated_student_recommendations.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Parse list-like strings in 'Past Events' and 'Recommended Events'\n",
    "df['Past Events'] = df['Past Events'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "df['Recommended Events'] = df['Recommended Events'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "\n",
    "# Available events and their domains\n",
    "events_data = {\n",
    "    'Event Name': [\n",
    "        'Hackathon', 'AI Summit', 'Data Science Workshop', 'Blockchain Basics',\n",
    "        'Tech Talk', 'Startup Pitch', 'Cybersecurity Conference', 'Innovation Summit',\n",
    "        'AI Research', 'Coding Marathon', 'UI/UX Workshop', 'Smart Agriculture',\n",
    "        'Cloud Computing Workshop', 'Data Analysis Bootcamp', 'Robotics Expo'\n",
    "    ],\n",
    "    'Domain': [\n",
    "        'Software Development', 'Artificial Intelligence', 'Data Science', 'Blockchain',\n",
    "        'General Technology', 'Entrepreneurship', 'Cybersecurity', 'Innovation & Research',\n",
    "        'AI & Machine Learning', 'Programming', 'Design', 'IoT & Smart Systems',\n",
    "        'Cloud Technology', 'Data Analytics', 'Robotics'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Domain mapping for student interests to event domains\n",
    "domain_mapping = {\n",
    "    'AI/ML': ['Artificial Intelligence', 'AI & Machine Learning'],\n",
    "    'Web Development': ['Software Development', 'Programming', 'Design'],\n",
    "    'Cybersecurity': ['Cybersecurity'],\n",
    "    'IoT': ['IoT & Smart Systems', 'Smart Agriculture'],\n",
    "    'Blockchain': ['Blockchain'],\n",
    "    'Embedded Systems': ['Robotics', 'Software Development'],\n",
    "    'AR/VR': ['Innovation & Research', 'Design'],\n",
    "    'Cloud Computing': ['Cloud Technology', 'Cloud Computing Workshop']\n",
    "}\n",
    "\n",
    "# Create a reverse mapping from event domains to event names\n",
    "domain_to_events = dict(zip(events_data['Domain'], events_data['Event Name']))\n",
    "\n",
    "# Feature engineering: Combine Interest Domain and Past Events into a single text feature\n",
    "def create_student_profile(row):\n",
    "    profile = row['Interest Domain']\n",
    "    if row['Past Events']:\n",
    "        profile += ' ' + ' '.join(row['Past Events'])\n",
    "    return profile\n",
    "\n",
    "df['Profile'] = df.apply(create_student_profile, axis=1)\n",
    "\n",
    "# Vectorize profiles using TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "student_tfidf = tfidf.fit_transform(df['Profile'])\n",
    "event_tfidf = tfidf.transform([domain for domain in events_data['Domain']])\n",
    "\n",
    "# Compute cosine similarity between student profiles and event profiles\n",
    "similarity_matrix = cosine_similarity(student_tfidf, event_tfidf)\n",
    "\n",
    "# Enhanced recommendation function with weighted scoring\n",
    "def get_enhanced_recommendations(student_idx, cgpa, performance_score, interest_domain):\n",
    "    # Base eligibility: CGPA >= 7.0 and Performance Score >= 50\n",
    "    if cgpa < 7.0 or performance_score < 50:\n",
    "        return []\n",
    "    \n",
    "    # Get similarity scores for this student\n",
    "    sim_scores = similarity_matrix[student_idx]\n",
    "    \n",
    "    # Normalize CGPA (5.0-10.0 to 0-1) and Performance Score (30-100 to 0-1)\n",
    "    cgpa_weight = (cgpa - 5.0) / 5.0\n",
    "    perf_weight = (performance_score - 30) / 70\n",
    "    \n",
    "    # Combined weight (average of CGPA and Performance Score contribution)\n",
    "    student_weight = (cgpa_weight + perf_weight) / 2\n",
    "    \n",
    "    # Adjust similarity scores with student weight\n",
    "    weighted_scores = sim_scores * student_weight\n",
    "    \n",
    "    # Map interest domain to possible event domains\n",
    "    possible_domains = domain_mapping.get(interest_domain, [interest_domain])\n",
    "    \n",
    "    # Get top similar events\n",
    "    event_indices = weighted_scores.argsort()[::-1]  # Sort in descending order\n",
    "    recommended_events = []\n",
    "    \n",
    "    for idx in event_indices:\n",
    "        event_domain = events_data['Domain'][idx]\n",
    "        event_name = domain_to_events[event_domain]\n",
    "        if event_domain in possible_domains and event_name not in recommended_events:\n",
    "            recommended_events.append(event_name)\n",
    "        if len(recommended_events) >= 2:  # Limit to 2 recommendations\n",
    "            break\n",
    "    \n",
    "    return recommended_events if recommended_events else []\n",
    "\n",
    "# Apply recommendations to the dataset\n",
    "df['Recommended Events'] = df.apply(\n",
    "    lambda row: get_enhanced_recommendations(\n",
    "        row.name, row['CGPA'], row['Performance Score'], row['Interest Domain']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Update the Message column based on recommendations\n",
    "df['Message'] = df['Recommended Events'].apply(\n",
    "    lambda x: \"We recommend attending high-quality events in your preferred domain. Keep up the good work!\"\n",
    "    if x else \"Focus on academics first. If you wish to attend an event, consult your class in-charge.\"\n",
    ")\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = r\"D:\\data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the updated dataset to CSV\n",
    "output_csv_path = os.path.join(output_dir, \"enhanced_student_recommendations.csv\")\n",
    "df.drop(columns=['Profile'], inplace=True)  # Drop temporary column\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Save the model (TF-IDF vectorizer and mappings) as a .pkl file\n",
    "model_data = {\n",
    "    'tfidf_vectorizer': tfidf,\n",
    "    'domain_to_events': domain_to_events,\n",
    "    'domain_mapping': domain_mapping,\n",
    "    'events_data': events_data\n",
    "}\n",
    "output_pkl_path = os.path.join(output_dir, \"recommendation_model.pkl\")\n",
    "with open(output_pkl_path, 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(f\"Updated dataset with enhanced recommendations saved to: {output_csv_path}\")\n",
    "print(f\"Recommendation model saved to: {output_pkl_path}\")\n",
    "print(\"\\nSample of the updated data (first 5 rows):\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04977aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
